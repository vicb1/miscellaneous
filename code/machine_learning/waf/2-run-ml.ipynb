{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bajenav\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3020: DtypeWarning: Columns (15,16,19,22,24,26,29,35,38,39,48,49,50,53,57,58,60,62,63,64,67,69,70,80) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_init = pd.read_csv('C:/_g_bak/WaferMLdata/df_joined.csv')\n",
    "# df_init = df_init[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of NaNs in df_all: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "df_all = df_init.set_index('WaferID')\n",
    "\n",
    "# The prefix_sep='_' makes each class has a unique name separated by the delimiter. \n",
    "# The drop_first=True drops one column from the resulted dummy features. The purpose is to avoid multicollinearity. \n",
    "df_all = pd.get_dummies(df_all, prefix_sep='_', drop_first=True)\n",
    "\n",
    "# If you want to impute your data either use a rolling average using .rolling() to replace missing value with the mean value of a rolling window. \n",
    "# If you want something more robust use module <b>missingpy</b> you can use MissForest for a randomforest based imputation\n",
    "# You can't fill the X_test NAs with the X_test mean, because in real life you won't have the X_test mean when you're predicting a sample. \n",
    "# You should use the X_train mean because this is the only data you actually have in hand (in 99% of the scenarios)\n",
    "df_all = df_all.astype(np.float64)\n",
    "df_all = df_all.replace([np.inf, -np.inf], np.nan)\n",
    "df_all = df_all.fillna(df_all.mean())\n",
    "df_all = df_all.fillna(0)\n",
    "print('# of NaNs in df_all:', df_all.isnull().values.sum())\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# df_train, df_test = train_test_split(df_all, test_size=0.5)\n",
    "\n",
    "y = df_all[\"Total Yield\"]\n",
    "X = df_all[df_all.columns.tolist()[1:]]\n",
    "# df_test_Y = df_test[\"Total Yield\"]\n",
    "# df_test_X = df_test[df_test.columns.tolist()[1:]]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)  # Don't cheat - fit only on training data # todo update this! \n",
    "X = scaler.transform(X)\n",
    "# df_test_X = scaler.transform(df_test_X)  # apply same transformation to test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import timeit\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn import ensemble\n",
    "from sklearn import neighbors\n",
    "from sklearn import tree\n",
    "\n",
    "models = []\n",
    "# models.append(('LinearRegression', linear_model.LinearRegression())) # LinAlgError: SVD did not converge in Linear Least Squares\n",
    "# models.append(('RANSACRegressor', linear_model.RANSACRegressor())) # more samples?\n",
    "# models.append(('Perceptron', linear_model.Perceptron()))  # needs labels?\n",
    "\n",
    "# models.append(('SGDRegressor', linear_model.SGDRegressor(max_iter=10000, tol=1e-3)))\n",
    "# models.append(('SGDRegressor2', linear_model.SGDRegressor(penalty='elasticnet', alpha=0.01,\n",
    "#                                   l1_ratio=0.25, fit_intercept=True,\n",
    "#                                   tol=1e-4)))\n",
    "# models.append(('Ridge', linear_model.Ridge(alpha=.5)))\n",
    "# models.append(('Lasso', linear_model.Lasso(alpha=0.1)))\n",
    "# models.append(('LassoLars', linear_model.LassoLars(alpha=0.1)))\n",
    "\n",
    "models.append(('TheilSenRegressor', linear_model.TheilSenRegressor()))\n",
    "models.append(('HuberRegressor', linear_model.HuberRegressor()))\n",
    "models.append(('SVR', svm.SVR(gamma='auto')))\n",
    "models.append(('svr_rbf', svm.SVR(kernel='rbf', C=100, gamma=0.1, epsilon=.1)))\n",
    "models.append(('svr_lin', svm.SVR(kernel='linear', C=100, gamma='auto')))\n",
    "models.append(('svr_poly', svm.SVR(kernel='poly', C=100, gamma='auto', degree=3, epsilon=.1, coef0=1)))\n",
    "\n",
    "models.append(('GradientBoostingRegressor', ensemble.GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=1, loss='ls')))\n",
    "models.append(('GradientBoostingRegressor2', ensemble.GradientBoostingRegressor(n_estimators=10)))\n",
    "models.append(('RandomForestRegressor', ensemble.RandomForestRegressor(n_estimators=10)))\n",
    "models.append(('RidgeCV', linear_model.RidgeCV(alphas=np.logspace(-6, 6, 13))))\n",
    "models.append(('BayesianRidge', linear_model.BayesianRidge()))\n",
    "models.append(('KNeighborsRegressor', neighbors.KNeighborsRegressor(5, weights='uniform')))\n",
    "models.append(('DecisionTreeRegressor', tree.DecisionTreeRegressor(max_depth=1)))\n",
    "\n",
    "# reg1 = linear_model.RidgeCV(alphas=np.logspace(-6, 6, 13))\n",
    "# reg2 = linear_model.BayesianRidge()\n",
    "# reg3 = ensemble.GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=1, random_state=0, loss='ls')\n",
    "# models.append(('VotingRegressor', ensemble.VotingRegressor(estimators=[('reg1', reg1), ('reg2', reg2), ('reg3', reg3)])))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    start = timeit.default_timer()\n",
    "    result = cross_val_score(model, X, y,  cv=5) # https://scikit-learn.org/stable/modules/cross_validation.html\n",
    "    print(name, '- learning time (mins): ', round((timeit.default_timer() - start) / 60.0, 1))\n",
    "    print(name, \"- Accuracy: %0.2f (+/- %0.2f)\" % (result.mean(), result.std() * 2))\n",
    "#     print(name, '- cross val accuracy:', result)\n",
    "    \n",
    "    names.append(name)\n",
    "    results.append(result)\n",
    "\n",
    "# for i in range(len(names)):\n",
    "#     print(names[i], '- in sample error:', results[i].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
